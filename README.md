# Big Data Viewer

## Vis√£o Geral
Big Data Viewer √© uma aplica√ß√£o web projetada para carregar e processar arquivos grandes (CSV, JSON, TXT) de forma eficiente, sem travar a interface do usu√°rio. A aplica√ß√£o utiliza tecnologias modernas como Lazy Loading, Web Workers e Streams API para oferecer uma experi√™ncia fluida ao lidar com grandes volumes de dados.

## Funcionalidades
- **Upload de Arquivos**: Os usu√°rios podem fazer upload de arquivos grandes nos formatos CSV, JSON ou TXT.
- **Lazy Loading**: Apenas partes do arquivo s√£o carregadas conforme necess√°rio, otimizando o uso de mem√≥ria.
- **Processamento em Segundo Plano**: O processamento dos dados √© realizado em um Web Worker, garantindo que a interface do usu√°rio permane√ßa responsiva.
- **Streaming de Dados**: A aplica√ß√£o l√™ os arquivos linha por linha utilizando a Streams API, permitindo um manuseio eficiente dos dados.
- **Filtros e Busca em Tempo Real**: Os usu√°rios podem filtrar e buscar nos dados enquanto eles est√£o sendo carregados.

## Tecnologias Utilizadas
- **JavaScript**: A principal linguagem de programa√ß√£o da aplica√ß√£o.
- **File API**: Utilizada para carregar arquivos do sistema do usu√°rio.
- **Web Workers**: Para processar dados em segundo plano sem bloquear a thread principal.
- **Streams API**: Para leitura eficiente de arquivos grandes.

## Etapas para Alcan√ßar os Conhecimentos em JavaScript

üî• **Projeto para treinar Otimiza√ß√£o de C√≥digo ‚Äì Lazy Loading, Web Workers, Streams**

### üìå Objetivo
Criar um app que carrega e processa arquivos grandes sem travar a interface, utilizando:
- Lazy Loading para carregar apenas parte do arquivo quando necess√°rio.
- Web Workers para processar os dados em segundo plano.
- Streams para ler os arquivos de maneira eficiente.

### ‚úÖ Etapas
1. **Carregamento de Arquivos Grandes (CSV, JSON, TXT)**  
   - [ ] Implementar o upload de arquivos utilizando a File API.
   - [ ] Validar o tipo de arquivo suportado (CSV, JSON, TXT).

2. **Lazy Loading**  
   - [ ] Implementar o carregamento parcial dos dados para evitar uso excessivo de mem√≥ria.
   - [ ] Exibir apenas uma parte dos dados na interface conforme necess√°rio.

3. **Processamento em Segundo Plano (Web Workers)**  
   - [ ] Criar um Web Worker para processar os dados em background.
   - [ ] Garantir que a interface do usu√°rio permane√ßa responsiva durante o processamento.

4. **Streaming de Dados**  
   - [ ] Utilizar a Streams API para ler os arquivos linha por linha.
   - [ ] Exibir os dados na interface conforme s√£o lidos.

5. **Filtros e Busca em Tempo Real**  
   - [ ] Implementar filtros para os dados carregados.
   - [ ] Adicionar funcionalidade de busca em tempo real.

### üåü Extras (Se quiser melhorar ainda mais!)
- [ ] Compress√£o e descompress√£o de arquivos com gzip.
- [ ] Cache local usando IndexedDB para evitar reprocessamento.
- [ ] Exporta√ß√£o dos dados processados para CSV ou JSON.

## Come√ßando

### Pr√©-requisitos
- Node.js e npm instalados na sua m√°quina.

### Instala√ß√£o
1. Clone o reposit√≥rio:
   ```
   git clone <repository-url>
   ```
2. Navegue at√© o diret√≥rio do projeto:
   ```
   cd big-data-viewer
   ```
3. Instale as depend√™ncias:
   ```
   npm install
   ```

### Executando a Aplica√ß√£o
1. Abra o arquivo `src/index.html` no seu navegador web.
2. Use o controle de upload para selecionar um arquivo grande (CSV, JSON ou TXT).
3. A aplica√ß√£o come√ßar√° a processar o arquivo, exibindo os dados conforme s√£o carregados.

## Contribuindo
Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para enviar um pull request ou abrir uma issue com sugest√µes ou melhorias.

## Licen√ßa
Este projeto est√° licenciado sob a Licen√ßa MIT. Consulte o arquivo LICENSE para mais detalhes.